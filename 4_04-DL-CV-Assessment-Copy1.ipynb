{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>\n",
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge: input (28,28,1)\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_train : (60000, 28, 28)\n",
      " y_train : (60000,)\n",
      " x_test : (10000, 28, 28)\n",
      " y_test : (10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {'x_train' : x_train, 'y_train' :y_train, 'x_test' : x_test, 'y_test' : y_test}\n",
    "[print(f\" {k} : {v.shape}\")for k,v in data_dict.items() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_image = x_train[0]\n",
    "print(single_image.shape)\n",
    "single_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6cac7d1fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(single_image) #(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(single_image))\n",
    "single_image.max() #ndarray.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "# x_train = x_train.reshape(:, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(10000,28,28,1) #channel 1 -> gray scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat = to_categorical(y_test)\n",
    "y_test_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel, Filter, Kernel \n",
    "###  Channel : In practicality, most input images have 3 channels(RGB), and that number only increases the deeper you go into a network. It’s pretty easy to think of channels, in general, as being a “view” of the image as a whole, emphasising some aspects, de-emphasising others.[(Reference : Irhum Shafkat)](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)\n",
    "![channel1](channel1.jpeg)\n",
    "* Most of the time, we deal with RGB images with three channels. [ (Photo by Andre Mouton) ](https://unsplash.com/photos/_d3sppFprWI) \n",
    "\n",
    "###  A filter: A collection of kernels, in case of multiple channels\n",
    "![channel](channel.png)\n",
    "*  whereas in the 1 channel case, where the term filter and kernel are interchangeable,\n",
    "\n",
    "##  Each filter in a convolution layer produces one and only one output channel.\n",
    "1. Each of the kernels of the filter “slides” over their respective input channels, producing a processed version of each. Some kernels may have stronger weights than others, to give more emphasis to certain input channels than others (eg. a filter may have a red kernel channel with stronger weights than others, and hence, respond more to differences in the red channel features than the others).\n",
    "![output1](output1.gif)\n",
    "\n",
    "2. Each of the per-channel processed versions are then summed together to form one channel. The kernels of a filter each produce one version of each channel, and the filter as a whole produces one overall output channel.\n",
    "![output2](output2.gif)\n",
    "\n",
    "3.  Finally, then there’s the bias term. The way the bias term works here is that each output filter has one bias term. The bias gets added to the output channel so far to produce the final output channel.\n",
    "![output3](output3.gif)\n",
    "\n",
    "## 2D(7x7) input matrix with 3 channels (RGB) - each filter consists of 3 kernels( A filter is a collection of 3 kernels)\n",
    "\n",
    "### * Each filter actually happens to be a collection of kernels, with there being one kernel for every single input channel to the layer, and each kernel being unique.\n",
    "#### * Whereas in the 1 channel case, where the term filter and kernel are interchangeable.\n",
    "![filter](filter.png)\n",
    "\n",
    "### In case of CNN layer\n",
    "[cnn basic Irhum Shafkat](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)\n",
    "* <span style=\"color:red\"> **kernel**</span>, __*(3,3) matrix of weights*__ with only <span style=\"color:red\">9 parameters</span> for CNN\n",
    "```\n",
    "[[0,1,2],\n",
    " [2,2,0],\n",
    " [0,1,2]]      \n",
    "```\n",
    "“slides” over the __*2D input data(5,5 matrix)*__,``With stride =1 and valid padding(no padding)``, performing an elementwise multiplication with the part of the input it is currently on, and then summing up the results into a single output pixel. __*Output (3,3) matrix*__.\n",
    "\n",
    "* Convolutions allow us to do this transformation with only 9 parameters, with each output feature, instead of “looking at” every input feature, only getting to “look” at input features coming from roughly the same location. \n",
    "\n",
    "![kernel_slide](kernel_slide.gif)\n",
    "* The kernel repeats this process for every location it slides over, converting a 2D matrix of features into yet another 2D matrix of features. \n",
    "* The output features are essentially, the weighted sums (with the weights being the values of the kernel itself) of the input features located roughly in the same location of the output pixel on the input layer.\n",
    "\n",
    "###  In case of standard fully connected layer\n",
    "* 5×5=25 input features, weight matrix 25x9= 225 ,which is kernel in cnn layer, and 3×3=9 output features\n",
    "* We need weight matrix of 25×9 = <span style=\"color:red\">225 parameters</span>, with every output feature being the weighted sum of every single input feature.\n",
    "\n",
    "[Following contents are from the cnn artilce written by Sumit Saha\n",
    "](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
    "\n",
    "\n",
    "# Convolution Layer — The Kernel\n",
    "###  The role of the ConvNet is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction.\n",
    "### The Kernel shifts 9 times- convolution with same padding , zero padding with stride =1\n",
    "![Image_convlovedFeature](kernel.gif)\n",
    "\n",
    "Kernel/Filter, K = \n",
    "```\n",
    "1  0  1\n",
    "0  1  0\n",
    "1  0  1\n",
    "```\n",
    "* Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature\n",
    "* Image Dimensions = 5 (Height) x 5 (Breadth) x <span style=\"color:blue\">1 (Number of channels, eg. RGB)</span>\n",
    "In the above demonstration, the green section resembles our 5x5x1 input image, I. The element involved in carrying out the convolution operation in the first part of a Convolutional Layer is called the Kernel/Filter, K, represented in the color yellow. We have selected K as a 3x3x1 matrix.\n",
    "* The Kernel shifts 9 times because of Stride Length = 1 (Non-Strided), every time performing a matrix multiplication operation between K and the portion P of the image over which the kernel is hovering.\n",
    "\n",
    "# first instance of 'input_img * feature_k = convolved_feature'\n",
    "import numpy as np\n",
    "input_img = np.array(\n",
    "[[1, 1, 1],\n",
    " [0, 1, 1],\n",
    " [0, 0 ,1]]\n",
    ")\n",
    "feature_k = np.array(\n",
    "[[1, 0, 1],\n",
    " [0, 1, 0],\n",
    " [1, 0, 1]]\n",
    ")\n",
    "sum(sum(input_img*feature_k)) #4\n",
    "\n",
    "![cnn operation](cnnop.gif)\n",
    "* Convolution operation on a MxNx3 image matrix with a 3x3x3(width, height, channel-depth) Kernel/Filter, K,\n",
    "* In the case of images with <span style=\"color:blue\">multiple channels (e.g. RGB)</span>, the Kernel has the same depth(3) as that of the input image. Matrix Multiplication is performed between Kn(Kernel) and In(Input) stack ([K1, I1]; [K2, I2]; [K3, I3]) and all the results are summed with the bias to give us a squashed one-depth channel Convoluted Feature Output.\n",
    "\n",
    "### The objective of the Convolution Operation is to extract the high-level features such as edges, from the input image. \n",
    "* ConvNets need not be limited to only one Convolutional Layer. Conventionally, the first ConvLayer is responsible for capturing the Low-Level features such as edges, color, gradient orientation, etc. \n",
    "* With added layers, the architecture adapts to the High-Level features as well, giving us a network which has the wholesome understanding of images in the dataset, similar to how we would\n",
    "\n",
    "[cnn padding very useful](https://deeplizard.com/learn/video/qSTv_m-KFk0)\n",
    "\n",
    "# Padding :  \n",
    "## Pad the edges with extra, “fake” pixels (usually of value 0, hence the oft-used term “zero padding”)\n",
    "## The kernel when sliding can allow the original edge pixels to be at its center, while extending into the fake pixels beyond the edge, producing an output the same size as the input.\n",
    "### 1. In case of without padding :  ( valid padding)- default in Conv2D\n",
    "\n",
    "* Case1: Input(n,n): (6,6), Filter(f,f): (3,3), stride 1 => 4 by 4 matrix: (n-f+1) x (n-f+1)\n",
    "![padding1](padding1.png) \n",
    "* So if you take this gray scale image.<span style=\"color:green\">The pixel in the corner</span> will only get covers one time.(The pixels on the edge are never at the center of the kernel) but if you take <span style=\"color:red\">the middle pixel</span> it will get covered more than once basically what does that means is we have more info on that middle pixel so these are the two main downsides([Article](https://medium.com/@ayeshmanthaperera/what-is-padding-in-cnns-71b21fb0dd7))\n",
    "    * Shrinking outputs(If we start out with a 4 x 4 image, for example, then just after a convolutional layer or two, the resulting output may become almost meaningless with how small it becomes.)\n",
    "    * Loosing information on corners of the image( the information around the edges of the input.)\n",
    "\n",
    "\n",
    "* Case2: Input(n,n): (4,4), Filter(f,f): (3,3), stride 1 => 2 by 2 matrix: (n-f+1) x (n-f+1)\n",
    "![padding1](padding1_1.png)\n",
    "### To overcome this problem, we can introduce Padding to an image. (ex. same padding with zero padding)\n",
    "#### With each convolutional layer, just as we define how many filters to have and the size of the filters, we can also specify whether or not to use padding.\n",
    "\n",
    "\n",
    "###  2. Same padding with zero padding\n",
    "* It’s an additional layer(zero-padding: symmetrically adding zeroes to the input matrix) that we can add to the border of an image.For an example see the figure below there one more layer added to the ``4*4 image`` and now it has converted in to ``6*6 image``(If zero padding = 1, there will be one pixel thick around the original image with pixel value = 0. Also stride = 1)\n",
    "![padding2](padding2_1.png)\n",
    "### zero-padding\n",
    "    * zero-padding is a commonly used modification that allows the size of the input to be adjusted to our requirement. It is mostly used in designing the CNN layers when the dimensions of the input volume need to be preserved in the output volume.\n",
    "* So now there is more frame that covers the edge pixels of an image\n",
    "* The kernel(Filter,matrix of weights) when sliding can allow the original edge pixels to be at its center, while extending into the fake pixels(value 0) beyond the edge, producing an output the same size as the input.\n",
    "\n",
    "### padding test\n",
    "* x: input image of shape [2, 3], 1 channel\n",
    "* valid_pad: max pool with 2x2 kernel, stride 2 and VALID padding.\n",
    "* same_pad: max pool with 2x2 kernel, stride 2 and SAME padding (this is the classic way to go)\n",
    "\n",
    "#### The output shapes are:\n",
    "* valid_pad: here, no padding so the output shape is [1, 1]\n",
    "* same_pad: here, we pad the image to the shape [2, 4] (with -inf and then apply max pool), so the output shape is [1, 2]\n",
    "\n",
    "# Padding: same(padding) vs. valid(no padding)\n",
    "* When stride is 1 (more typical with convolution than pooling), we can think of the following distinction:\n",
    "\n",
    "* \"SAME\": output size is the same as input size. This requires the filter window to slip outside input map, hence the need to pad.\n",
    "* \"VALID\": Filter window stays at valid position inside input map, so output size shrinks by filter_size - 1. No padding occurs.\n",
    "\n",
    "## 1. Same padding (with zero padding)\n",
    "### 1)  Same Padding:   the dimensionality is either increased or remains the same through covolution operation\n",
    "* When we augment the 5x5x1 image into a 7x7x1 image with <span style=\"color:red\">0(zero) added ouside</span> and then apply the 3x3x1 kernel over it, we find that the convolved matrix turns out to be of dimensions 5x5x1. <span style=\"color:red\">striding = 1</span>\n",
    "![same padding](samepadding.gif)\n",
    "\n",
    "### 2)  Striding = 2  :  convolved feature is reduced in dimensionality, enen though same padding\n",
    "* As for 5x5x1 input image if we perform with kernel(3x3x1), striding =2 with the same padding, output matrix dimensions is decreased to (3x3x1). <span style=\"color:red\">striding = 2</span>\n",
    "\n",
    "![valid padding](validpadding.gif)\n",
    "\n",
    "## 2. Valid paddding( no padding) - default in Conv2D\n",
    "### Valid Padding(no padding) :  convolved feature is reduced in dimensionality as compared to the input through covolution operation\n",
    "* As for 5x5x1 input image if we perform with kernel(3x3x1), striding =1 with the valid padding(no padding), we are presented matrix with a reduced dimension same as the Kernel (3x3x1) itself. <span style=\"color:red\">striding = 1</span>\n",
    "\n",
    "* As for 5x5x1 input image if we perform with kernel(3x3x1), striding =2 with the valid padding(no padding), we are presented matrix with a reduced dimension (2x2x1). <span style=\"color:red\">striding = 2</span>\n",
    "\n",
    "\n",
    "\n",
    "![pad stride](padstride.png)\n",
    "\n",
    "# Pooling Layer : Similar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature.\n",
    "*  This is to decrease the computational power required to process the data through dimensionality reduction. Furthermore, it is useful for extracting dominant features which are rotational and positional invariant(preserve same identity, category (etc) even if ratated or position changed), thus maintaining the process of effectively training of the model.\n",
    "![pooling](pooling.gif)\n",
    "* Max pooling : 3x3 pooling over 5x5 convolved feature\n",
    "\n",
    "* Max Pooling : performs as a Noise Suppressant. It discards the noisy activations altogether and also performs de-noising along with dimensionality reduction. \n",
    "* Average Pooling : simply performs dimensionality reduction as a noise suppressing mechanism. Hence, we can say that Max Pooling performs a lot better than Average Pooling.\n",
    "![pooling](pooling.jpeg)\n",
    "\n",
    "* The Convolutional Layer and the Pooling Layer, together form the i-th layer of a Convolutional Neural Network. \n",
    "\n",
    "*  Often when running a convolution layer, you want an output with a lower size than the input. This is commonplace in convolutional neural networks, where the size of the spatial dimensions are reduced when increasing the number of channels. -> \n",
    "    * striding = 2(downsizing by roughly a factor of 2), 3(downsizing roughly by factor 3) and so on. \n",
    "    * pooling(ex. max pooling)\n",
    "\n",
    "[kernel feature size guide ](https://www.sicara.ai/blog/2019-10-31-convolutional-layer-convolution-kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "\n",
    "### Valid paddding( no padding) - default in Conv2D\n",
    "* Valid Padding(no padding) : convolved feature is reduced in dimensionality as compared to the input through covolution operation¶\n",
    "* As for 28x128x1 input image if we perform with kernel(3x3) and 32 filters(3x3x3), striding =1 with the valid padding(no padding), we are presented matrix with a reduced dimension (128, 128, 32) <- 130 - 3 + 1 = 128. striding = 1\n",
    "\n",
    "### 2D(28x28) input matrix with 1 channel(grayscale) - filter is a kernel \n",
    "#### Conv2D(filters=32, kernel_size=(3,3),input_shape=(28, 28, 1), activation='relu',)\n",
    "* Input volume (28x28x1) x[:,:,0]\n",
    "* Filter(32 Filters), Bias(32 Bias)\n",
    "    * Filter w0(3x3x1)-w0[:,:,0] , Bias b0(1x1x1)-b0[:,:,0]\n",
    "    * Filter w1(3x3x1)-w1[:,:,0] , Bias b1(1x1x1)-b0[:,:,0]\n",
    "    * Filter w2(3x3x1)-w2[:,:,0] , Bias b2(1x1x1)-b0[:,:,0]\n",
    "    * ....\n",
    "    * Filter w31(3x3x1)-w31[:,:,0] , Bias b31(1x1x1)-b0[:,:,0]\n",
    "* kernel(3,3) matrix of weights with only 9 parameters for CNN slides over the 2D input data(28,28 matrix)\n",
    "with stride =1 and valid padding(no padding).\n",
    "    * 28 - 3 + 1 = 26 (Input shape(28x28), Filter shape(3x3) with 32 filters, Output shape(26x26))\n",
    "    * **output shape -> (,26,26,32)**\n",
    "\n",
    "#### MaxPool2D(pool_size=(2, 2))\n",
    "* pool size(2,2), stride=2 stride over (26,26) -> 26/2 => 13\n",
    "* **output shape -> (,13,13,32)**\n",
    "\n",
    "#### Flatten()\n",
    "* 13x13x32 -> **output(,5408)**\n",
    "\n",
    "#### Dense(128, activation='relu')\n",
    "* 128 neurons hidden layer -> **output (,128)**\n",
    "\n",
    "#### Dense(10, activation='softmax')\n",
    "* classifier with 10 classes -> **output (,10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(3,3)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile: \n",
    "we want to decide a model architecture, this is the number of hidden layers and activation functions, etc. \n",
    "The compilation steps also asks you to define the loss function and kind of optimizer you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']) #'mse' for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### fit:\n",
    " we need to train our model so that the parameters get tuned to provide the correct outputs for a given input. We do this by feeding inputs at the input layer and then getting an output, we then calculate the loss function using the output and use backpropagation to tune the model parameters. This will **fit** the model parameters to the data.\n",
    " [compile fit predict examples](https://datascience.stackexchange.com/questions/46124/what-do-compile-fit-and-predict-do-in-keras-sequential-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 0.3944 - accuracy: 0.8589 - val_loss: 0.3226 - val_accuracy: 0.8823\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.2697 - accuracy: 0.9019 - val_loss: 0.2761 - val_accuracy: 0.8989\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.2253 - accuracy: 0.9176 - val_loss: 0.2774 - val_accuracy: 0.8968\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.1927 - accuracy: 0.9291 - val_loss: 0.2548 - val_accuracy: 0.9083\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1662 - accuracy: 0.9376 - val_loss: 0.2472 - val_accuracy: 0.9137\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1442 - accuracy: 0.9467 - val_loss: 0.2576 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1227 - accuracy: 0.9536 - val_loss: 0.2706 - val_accuracy: 0.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6cac0631d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_cat, epochs=20, validation_data=(x_test, y_test_cat), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6cac0631d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.39443360428412755,\n",
       "  0.2697416810631752,\n",
       "  0.22528006603916487,\n",
       "  0.19269870396256447,\n",
       "  0.16618558723181487,\n",
       "  0.14419147512714067,\n",
       "  0.1227092637921373],\n",
       " 'accuracy': [0.8588667,\n",
       "  0.9018833,\n",
       "  0.91761667,\n",
       "  0.9291,\n",
       "  0.93763334,\n",
       "  0.9467,\n",
       "  0.9536333],\n",
       " 'val_loss': [0.32260251232385634,\n",
       "  0.2760717653989792,\n",
       "  0.2773921070337296,\n",
       "  0.25476971052885056,\n",
       "  0.24715050470232963,\n",
       "  0.25761024999022486,\n",
       "  0.2706335971802473],\n",
       " 'val_accuracy': [0.8823, 0.8989, 0.8968, 0.9083, 0.9137, 0.912, 0.9143]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.394434</td>\n",
       "      <td>0.858867</td>\n",
       "      <td>0.322603</td>\n",
       "      <td>0.8823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269742</td>\n",
       "      <td>0.901883</td>\n",
       "      <td>0.276072</td>\n",
       "      <td>0.8989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.225280</td>\n",
       "      <td>0.917617</td>\n",
       "      <td>0.277392</td>\n",
       "      <td>0.8968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192699</td>\n",
       "      <td>0.929100</td>\n",
       "      <td>0.254770</td>\n",
       "      <td>0.9083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.166186</td>\n",
       "      <td>0.937633</td>\n",
       "      <td>0.247151</td>\n",
       "      <td>0.9137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.144191</td>\n",
       "      <td>0.946700</td>\n",
       "      <td>0.257610</td>\n",
       "      <td>0.9120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.122709</td>\n",
       "      <td>0.953633</td>\n",
       "      <td>0.270634</td>\n",
       "      <td>0.9143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.394434  0.858867  0.322603        0.8823\n",
       "1  0.269742  0.901883  0.276072        0.8989\n",
       "2  0.225280  0.917617  0.277392        0.8968\n",
       "3  0.192699  0.929100  0.254770        0.9083\n",
       "4  0.166186  0.937633  0.247151        0.9137\n",
       "5  0.144191  0.946700  0.257610        0.9120\n",
       "6  0.122709  0.953633  0.270634        0.9143"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.DataFrame(model.history.history)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6cac1d6750>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6c4421b8d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.evaluate\n",
    "Returns the loss value & metrics values for the model in test mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2706335971802473, 0.9143]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test_cat, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a model architecture and we have a file containing all the model parameters with the best values found to map the inputs to an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict : use this model to do some feed-forward passes to predict novel inputs. (predict)\n",
    "#### predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option1 : model.predict\n",
    "predictions1 = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.8469178e-05, 3.1430306e-11, 2.5565068e-05, ..., 2.7824477e-03,\n",
       "        4.4110152e-06, 9.9694532e-01],\n",
       "       [4.9970595e-06, 5.3750620e-14, 9.9997640e-01, ..., 2.6371180e-17,\n",
       "        2.3426369e-12, 2.1390837e-18],\n",
       "       [3.2375143e-09, 1.0000000e+00, 6.6519398e-12, ..., 1.2436848e-15,\n",
       "        1.7728138e-13, 1.0065021e-15],\n",
       "       ...,\n",
       "       [1.1257185e-09, 9.8589912e-12, 5.6545855e-07, ..., 4.0240110e-08,\n",
       "        9.9998367e-01, 5.0982296e-12],\n",
       "       [1.5822638e-09, 9.9999690e-01, 3.1873523e-10, ..., 1.5506406e-15,\n",
       "        2.8363024e-13, 9.6761037e-12],\n",
       "       [1.9172861e-05, 4.4205159e-08, 2.6065869e-05, ..., 1.2427149e-02,\n",
       "        4.8612562e-04, 7.0619171e-06]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions1.shape)\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ np.argmax(x) for x in predictions1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2, 1, 1, 6, 1, 4, 6, 5, 7]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.argmax(x) for x in predictions1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#option2 : model.predict_classes\n",
    "predictions = model.predict_classes(x_test)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test_cat.shape)\n",
    "y_test_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![precision_reacall](precision_recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* precision = tp / (tp + fp) \n",
    "* recall = tp / (tp + fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      1000\n",
      "           1       0.99      0.99      0.99      1000\n",
      "           2       0.92      0.80      0.86      1000\n",
      "           3       0.93      0.90      0.91      1000\n",
      "           4       0.80      0.93      0.86      1000\n",
      "           5       0.98      0.98      0.98      1000\n",
      "           6       0.77      0.75      0.76      1000\n",
      "           7       0.94      0.98      0.96      1000\n",
      "           8       0.99      0.97      0.98      1000\n",
      "           9       0.98      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.92      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
